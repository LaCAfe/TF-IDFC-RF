{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import  mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from textvec.vectorizers import TfrfVectorizer\n",
    "#from textvec.vectorizers import TfIcfVectorizer\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "#from textvec import vectorizers\n",
    "#from textvec.vectorizers import BaseBinaryFitter\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "global DIR\n",
    "DIR = '/Users/gustavo/Downloads/TF-IDFC-RF-master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBinaryFitter(TransformerMixin):\n",
    "    \"\"\"Base class for supervised methods (supports only binary classification).\n",
    "    Should not be used as by itself.\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    smooth_df : boolean or int, default=True\n",
    "        Smooth df weights by adding one to document frequencies, as if an\n",
    "        extra document was seen containing every term in the collection\n",
    "        exactly once. Prevents zero divisions.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm='l2', smooth_df=False, sublinear_tf=False):\n",
    "        self.norm = norm\n",
    "        self.smooth_df = smooth_df\n",
    "        self.sublinear_tf = sublinear_tf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        pos_samples = sp.spdiags(y, 0, n_samples, n_samples)\n",
    "        neg_samples = sp.spdiags(1 - y, 0, n_samples, n_samples)\n",
    "\n",
    "        self._n_pos = np.sum(y)\n",
    "        self._n_neg = np.sum(1-y)\n",
    "        \n",
    "        X_pos = pos_samples * X\n",
    "        X_neg = neg_samples * X\n",
    "\n",
    "        tp = np.bincount(X_pos.indices, minlength=n_features)\n",
    "        fp = np.sum(y) - tp\n",
    "        tn = np.bincount(X_neg.indices, minlength=n_features)\n",
    "        fn = np.sum(1 - y) - tn\n",
    "\n",
    "        self._n_samples = n_samples\n",
    "        self._n_features = n_features\n",
    "\n",
    "        self._tp = tp\n",
    "        self._fp = fp\n",
    "        self._fn = fn\n",
    "        self._tn = tn\n",
    "        self._p = np.sum(y)\n",
    "        self._n = np.sum(1 - y)\n",
    "\n",
    "        if self.smooth_df:\n",
    "            self._n_samples += int(self.smooth_df)\n",
    "            self._tp += int(self.smooth_df)\n",
    "            self._fp += int(self.smooth_df)\n",
    "            self._fn += int(self.smooth_df)\n",
    "            self._tn += int(self.smooth_df)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPolarityCross():\n",
    "    data = pd.read_csv(DIR + 'polarity2.arff.csv',sep='##,##')  \n",
    "   # df = pd.read_csv(path, encoding = \"ISO-8859-1\")\n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='pos','y']=int(1)\n",
    "    data.loc[data['y']=='neg','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSarcasmCross():\n",
    "    data = pd.read_csv(DIR + 'amazon-sarcarsm-limpo3-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='ironic','y']=int(1)\n",
    "    data.loc[data['y']=='regular','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSubjectivityCross():\n",
    "    data = pd.read_csv(DIR + 'subjectivity-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='subjetivas','y']=int(1)\n",
    "    data.loc[data['y']=='objetivas','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMovieReviewCross():\n",
    "    data = pd.read_csv(DIR + 'movie-review-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='neg','y']=int(1)\n",
    "    data.loc[data['y']=='pos','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_sparse_format(array, dtype=np.float64):\n",
    "    if sp.issparse(array):\n",
    "        if array.dtype != dtype:\n",
    "            array = array.astype(dtype)\n",
    "    else:\n",
    "        array = sp.csr_matrix(array, dtype=dtype)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfcrfVectorizer1(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        np.sqrt(X.data, X.data)     \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp\n",
    "        \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=D+C\n",
    "        f = self._n_features\n",
    "\n",
    "        #k = np.log2(2 + tp / fn)\n",
    "      #  N=tp+fn+tn+fp\n",
    "        #print(N)\n",
    "        \n",
    "        #k = np.log(10+(A)/C)* (D/np.log(10+(A)/C))\n",
    "       # k = np.log(10+(A)/C) * (D+B) *N *(np.log(10+(C)/B+D)) 0.8444\n",
    "        #k = np.log(10+(A)/C) * (D+B) *N *(np.log(10+(C)/B))0.8435\n",
    "       # k = np.log(10+(A)/C)* (D/np.log(10+(A)/C)) *(N/np.log(10+(C)/B)) 0.843\n",
    "       #  k = np.log(10+(A)/C)* (D/np.log(10+(A)/C)) 0.8415\n",
    "#    k = np.log(10+(A)/C)* (D/np.log(10+(A)/C)) *(N/np.log(10+(B)/D)) 0.8405\n",
    "       #  k = np.log(10+(A)/C)* (B/np.log(10+(A)/C))  0.8375  \n",
    "#    k = np.log(10+(A)/C)*np.log(10+(pow(D,2))/B) 0.834 -> facil de explicar\n",
    "     #   k = np.log2(2 + A / C)/np.log2(2 + A / C) --> 0.8195\n",
    "         #k = np.log(10+A/C) -->0.818\n",
    "       # k = np.log2(2 + tp / fn) --> 0.8065\n",
    "        \n",
    "     #   k = np.log(10+(A)/C)* (D/np.log(10+(A)/C)) *(N/np.log(10+(C)/B))\n",
    "        \n",
    "        #k = np.log(10+(A)/C)* (D/np.log(10+(A)/C))*(N/np.log(10+(C)/B))\n",
    "        \n",
    "       # k = np.log(10+(A)/C)* D  *np.log(10+(C)/B)\n",
    "        #k = np.log(10+(A)/C) * (D+B) *N *(np.log(10+(C)/B+D))\n",
    "        \n",
    "        \n",
    "        #todos os resultados foram gerados com esse abaixo:\n",
    "        #k = np.log(10+(A)/C) * (D+B) *N *(np.log(10+(C)/B+D))\n",
    "        \n",
    "        n_pos=self._n_pos\n",
    "        n_neg=self._n_neg\n",
    "        N=n_pos+n_neg\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        Dtotal_ti2=np.where(w == 1, self._n_pos, self._n_neg)    \n",
    "        A=A\n",
    "        B=B\n",
    "        C=C\n",
    "        D=D\n",
    "        IDF=np.log(N/(A+C)) \n",
    "        k=np.log2(2+(np.maximum(A,C)/(2+np.minimum(A,C)))* (np.sqrt(B+D)))#(np.log2(np.maximum(A, B+D)))\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIGMVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        IGM=np.maximum(A,C)/((np.maximum(A,C)*1)+(np.minimum(A,C)*2))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQRTTfIGMVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "         #   X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        np.sqrt(X.data, X.data)   \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        IGM=np.maximum(A,C)/(((np.maximum(A,C)*1)+(np.minimum(A,C)*2)))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIGMimpVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1 \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        IGM = np.maximum(A, C) / (((np.maximum(A, C) * 1) + (np.minimum(A, C) * 2) + np.log10(Dtotal_ti / np.maximum(A, C))))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQRTTfIGMimpVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1 \n",
    "        np.sqrt(X.data, X.data)      \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        IGM = np.maximum(A, C) / (((np.maximum(A, C) * 1) + (np.minimum(A, C) * 2) + np.log10(Dtotal_ti / np.maximum(A, C))))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfDELTAidf(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp\n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        k=np.log2(2+((NP+C+0.5)/(A*NN+0.5)))\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfrfVectorizer(BaseBinaryFitter, BaseEstimator):\n",
    "    \"\"\"Supervised method (supports ONLY binary classification)\n",
    "    transform a count matrix to a normalized Tfrf representation\n",
    "    Tf means term-frequency while RF means relevance frequency.\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    smooth_df : boolean or int, default=True\n",
    "        Smooth df weights by adding one to document frequencies, as if an\n",
    "        extra document was seen containing every term in the collection\n",
    "        exactly once. Prevents zero divisions.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    .. [M. Lan, C. L. Tan, J. Su, and Y. Lu] `Supervised and traditional\n",
    "                term weighting methods for automatic text categorization`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn = self._tn\n",
    "        f = self._n_features\n",
    "\n",
    "        k = np.log2(2 + (tp / np.maximum(1,tn)))\n",
    "\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIcfVectorizer(BaseBinaryFitter,TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Supervised method (supports multiclass) to transform\n",
    "    a count matrix to a normalized Tficf representation\n",
    "    Tf means term-frequency while ICF means inverse category frequency.\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    .. [0] `https://arxiv.org/pdf/1012.2609.pdf`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, norm=None, sublinear_tf=False, smooth_df=False):\n",
    "        self.norm = norm\n",
    "        self.sublinear_tf = sublinear_tf\n",
    "        self.smooth_df = smooth_df\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        pos_samples = sp.spdiags(y, 0, n_samples, n_samples)\n",
    "        neg_samples = sp.spdiags(1 - y, 0, n_samples, n_samples)\n",
    "\n",
    "        X_pos = pos_samples * X\n",
    "        X_neg = neg_samples * X\n",
    "\n",
    "        tp = np.bincount(X_pos.indices, minlength=n_features)\n",
    "        fp = np.sum(y) - tp\n",
    "        tn = np.bincount(X_neg.indices, minlength=n_features)\n",
    "        fn = np.sum(1 - y) - tn\n",
    "        if self.smooth_df:\n",
    "            self._n_samples += int(self.smooth_df)\n",
    "            self._tp += int(self.smooth_df)\n",
    "            self._fp += int(self.smooth_df)\n",
    "            self._fn += int(self.smooth_df)\n",
    "            self._tn += int(self.smooth_df)\n",
    "\n",
    "        samples = []\n",
    "        self.number_of_classes = len(np.unique(y))\n",
    "        for val in range(self.number_of_classes):\n",
    "            class_mask = sp.spdiags(y == val, 0, n_samples, n_samples)\n",
    "            samples.append(np.bincount(\n",
    "                (class_mask * X).indices, minlength=n_features))\n",
    "        samples = np.array(samples)\n",
    "        self.corpus_occurence = np.sum(samples != 0, axis=0)\n",
    "        self.k = (1+np.log(n_samples/(tp+tn))) * (1 + np.log(self.number_of_classes / self.corpus_occurence))\n",
    "        self._n_features = n_features\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, min_freq=1):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        f = self._n_features\n",
    "        X = X * sp.spdiags(self.k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process (num_attributes, vectorizer, cross_val_num, classifier):\n",
    "  #  clf = svm.SVC(kernel='linear', C=1)\n",
    "    clf = classifier\n",
    "    pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('vetorizer', vectorizer),\n",
    "                     ('reduce_dim', SelectKBest(chi2, k=num_attributes)),\n",
    "                     ('clf', clf)])\n",
    "    scores = cross_val_score(pipe,X.values,y.values,cv=cross_val_num, n_jobs=8)\n",
    "    scores\n",
    "    soma=0\n",
    "    for x in scores:   \n",
    "        soma=soma+x\n",
    "    return soma/cross_val_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAll (array_val, vectorizer, cross_val_num, classifier):\n",
    "    lst = []\n",
    "    \n",
    "    for x in array_val:  \n",
    "        lst.append(process(x, vectorizer, cross_val_num, classifier))\n",
    "\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dc53ceb1dd7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadMovieReviewCross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#readSubjectivityCross() #readSarcasmCross() #readPolarityCross()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresultsTFIGM_svm_MR_MR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfIGMVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresultsTFIGM_svm_MR_MR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresultsSQRTTFIGM_svm_MR_MR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQRTTfIGMVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4d1dddffb315>\u001b[0m in \u001b[0;36mprocessAll\u001b[0;34m(array_val, vectorizer, cross_val_num, classifier)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marray_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e9aa138d05e0>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(num_attributes, vectorizer, cross_val_num, classifier)\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0;34m(\u001b[0m\u001b[0;34m'reduce_dim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      ('clf', clf)])\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msoma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lst=[500,1000,2000,4000,6000,8000,10000,12000,14000]\n",
    "X,y = readMovieReviewCross()#readSubjectivityCross() #readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_MR = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsSQRTTFIGM_svm_MR_MR = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_MR = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_MR = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_MR = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_MR = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_MR = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_MR = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_MR = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_MR = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_MR = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_MR = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_MR = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_MR = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_MR = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_MR = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_MR = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_MR = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_MR = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_MR = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_MR))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_MR))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_MR))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_MR))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_MR))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_MR))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_MR))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_MR))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_MR))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_MR))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_MR))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_MR))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_MR))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_MR))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_MR))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_MR))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_sub))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_sub))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_sub))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = readSubjectivityCross() #readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_sub = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_sub = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_sub = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_sub = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_sub = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_sub = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_sub = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_sub = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_sub = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_sub = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_sub = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_sub = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_sub = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_sub = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_sub = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_sub = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_sub = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_sub = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_sub = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_sub = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_sub))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_sub))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_sub))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_sub))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_sub))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_sub))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_sub))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_sub))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_sub))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_sub))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_sub))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_sub))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_sub))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_sub))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_sub))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_sub))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_sub))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_sub))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_sub))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_sar = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_sar = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_sar = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_sar = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_sar = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_sar = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_sar = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_sar = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_sar = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_sar = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_sar = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_sar = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_sar = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_sar = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_sar = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_sar = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_sar = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_sar = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_sar = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_sar = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_sar))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_sar))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_sar))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_sar))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_sar))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_sar))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_sar))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_sar))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_sar))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_sar))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_sar))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_sar))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_sar))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_sar))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_sar))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_sar))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_sar))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_sar))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_sar))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_sar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity dataset\n",
      "[500, 1000, 2000, 4000, 6000, 8000, 10000, 12000, 14000]\n"
     ]
    }
   ],
   "source": [
    "X,y = readPolarityCross()\n",
    "print (\"Polarity dataset\")\n",
    "print (lst)\n",
    "resultsTFIGM_svm_MR_Pol = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_Pol = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_Pol = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_Pol = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsICF_svm_MR_Pol = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_Pol = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_Pol = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_Pol = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_Pol = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_Pol = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_Pol = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_Pol = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_Pol = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_Pol = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsICF_mnb_MR_Pol = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_Pol = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_Pol = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_Pol = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_Pol = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_Pol = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_Pol))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_Pol))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_Pol))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_Pol))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_Pol))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_Pol))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_Pol))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_Pol))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_Pol))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_Pol))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_Pol))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_Pol))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_Pol))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_Pol))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_Pol))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_Pol))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_Pol))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_Pol))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_Pol))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_Pol))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
