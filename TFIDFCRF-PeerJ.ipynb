{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import  mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from textvec.vectorizers import TfrfVectorizer\n",
    "#from textvec.vectorizers import TfIcfVectorizer\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "#from textvec import vectorizers\n",
    "#from textvec.vectorizers import BaseBinaryFitter\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "global DIR\n",
    "DIR = '/Users/gustavo/Downloads/TF-IDFC-RF-master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBinaryFitter(TransformerMixin):\n",
    "    \"\"\"Base class for supervised methods (supports only binary classification).\n",
    "    Should not be used as by itself.\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    smooth_df : boolean or int, default=True\n",
    "        Smooth df weights by adding one to document frequencies, as if an\n",
    "        extra document was seen containing every term in the collection\n",
    "        exactly once. Prevents zero divisions.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm='l2', smooth_df=False, sublinear_tf=False):\n",
    "        self.norm = norm\n",
    "        self.smooth_df = smooth_df\n",
    "        self.sublinear_tf = sublinear_tf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        pos_samples = sp.spdiags(y, 0, n_samples, n_samples)\n",
    "        neg_samples = sp.spdiags(1 - y, 0, n_samples, n_samples)\n",
    "\n",
    "        self._n_pos = np.sum(y)\n",
    "        self._n_neg = np.sum(1-y)\n",
    "        \n",
    "        X_pos = pos_samples * X\n",
    "        X_neg = neg_samples * X\n",
    "\n",
    "        tp = np.bincount(X_pos.indices, minlength=n_features)\n",
    "        fp = np.sum(y) - tp\n",
    "        tn = np.bincount(X_neg.indices, minlength=n_features)\n",
    "        fn = np.sum(1 - y) - tn\n",
    "\n",
    "        self._n_samples = n_samples\n",
    "        self._n_features = n_features\n",
    "\n",
    "        self._tp = tp\n",
    "        self._fp = fp\n",
    "        self._fn = fn\n",
    "        self._tn = tn\n",
    "        self._p = np.sum(y)\n",
    "        self._n = np.sum(1 - y)\n",
    "\n",
    "        if self.smooth_df:\n",
    "            self._n_samples += int(self.smooth_df)\n",
    "            self._tp += int(self.smooth_df)\n",
    "            self._fp += int(self.smooth_df)\n",
    "            self._fn += int(self.smooth_df)\n",
    "            self._tn += int(self.smooth_df)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPolarityCross():\n",
    "    data = pd.read_csv(DIR + 'polarity2.arff.csv',sep='##,##')  \n",
    "   # df = pd.read_csv(path, encoding = \"ISO-8859-1\")\n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='pos','y']=int(1)\n",
    "    data.loc[data['y']=='neg','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSarcasmCross():\n",
    "    data = pd.read_csv(DIR + 'amazon-sarcarsm-limpo3-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='ironic','y']=int(1)\n",
    "    data.loc[data['y']=='regular','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSubjectivityCross():\n",
    "    data = pd.read_csv(DIR + 'subjectivity-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='subjetivas','y']=int(1)\n",
    "    data.loc[data['y']=='objetivas','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMovieReviewCross():\n",
    "    data = pd.read_csv(DIR + 'movie-review-raw.arff.csv',sep='##,##')  \n",
    "    #transformando as classes para bin치rios inteiros\n",
    "    data.loc[data['y']=='neg','y']=int(1)\n",
    "    data.loc[data['y']=='pos','y']=int(0)\n",
    "    final=pd.DataFrame({\"text\": data['text'], \"y\": data['y'].astype('int')})\n",
    "    X=final['text']\n",
    "    y=final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_sparse_format(array, dtype=np.float64):\n",
    "    if sp.issparse(array):\n",
    "        if array.dtype != dtype:\n",
    "            array = array.astype(dtype)\n",
    "    else:\n",
    "        array = sp.csr_matrix(array, dtype=dtype)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfcrfVectorizer1(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        np.sqrt(X.data, X.data)     \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp\n",
    "        \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=D+C\n",
    "        f = self._n_features\n",
    "        \n",
    "        n_pos=self._n_pos\n",
    "        n_neg=self._n_neg\n",
    "        N=n_pos+n_neg\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        Dtotal_ti2=np.where(w == 1, self._n_pos, self._n_neg)    \n",
    "        A=A\n",
    "        B=B\n",
    "        C=C\n",
    "        D=D\n",
    "        IDF=np.log(N/(A+C)) \n",
    "        k=np.log2(2+(np.maximum(A,C)/(2+np.minimum(A,C)))* (np.sqrt(B+D)))#(np.log2(np.maximum(A, B+D)))\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIGMVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        IGM=np.maximum(A,C)/((np.maximum(A,C)*1)+(np.minimum(A,C)*2))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQRTTfIGMVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "         #   X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        np.sqrt(X.data, X.data)   \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        IGM=np.maximum(A,C)/(((np.maximum(A,C)*1)+(np.minimum(A,C)*2)))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIGMimpVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1 \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        IGM = np.maximum(A, C) / (((np.maximum(A, C) * 1) + (np.minimum(A, C) * 2) + np.log10(Dtotal_ti / np.maximum(A, C))))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQRTTfIGMimpVectorizer(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1 \n",
    "        np.sqrt(X.data, X.data)      \n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp \n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        \n",
    "        #concatena A com C\n",
    "        vet1 = np.concatenate(([A], [C]), axis=0)\n",
    "        #qual o indice da maior classe\n",
    "        w = np.argmax(vet1,axis=0)\n",
    "        \n",
    "        #here, 0 is positive, since A is in the first line and C in the second\n",
    "        Dtotal_ti=np.where(w == 0, self._n_pos, self._n_neg)\n",
    "        IGM = np.maximum(A, C) / (((np.maximum(A, C) * 1) + (np.minimum(A, C) * 2) + np.log10(Dtotal_ti / np.maximum(A, C))))\n",
    "        k=(1 + (7*IGM));\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfDELTAidf(BaseBinaryFitter):\n",
    "    def transform(self, X):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn=self._tn\n",
    "        fp=self._fp\n",
    "        A=tp\n",
    "        B=fp\n",
    "        D=fn\n",
    "        C=tn\n",
    "        NP=A+B\n",
    "        NN=C+D\n",
    "        f = self._n_features\n",
    "        N=tp+fn+tn+fp\n",
    "        k=np.log2(2+((NP+C+0.5)/(A*NN+0.5)))\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfrfVectorizer(BaseBinaryFitter, BaseEstimator):\n",
    "    \"\"\"Supervised method (supports ONLY binary classification)\n",
    "    transform a count matrix to a normalized Tfrf representation\n",
    "    Tf means term-frequency while RF means relevance frequency.\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    smooth_df : boolean or int, default=True\n",
    "        Smooth df weights by adding one to document frequencies, as if an\n",
    "        extra document was seen containing every term in the collection\n",
    "        exactly once. Prevents zero divisions.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    .. [M. Lan, C. L. Tan, J. Su, and Y. Lu] `Supervised and traditional\n",
    "                term weighting methods for automatic text categorization`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_sparse_format(X)\n",
    "        if self.sublinear_tf:\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "\n",
    "        tp = self._tp\n",
    "        fn = self._fn\n",
    "        tn = self._tn\n",
    "        f = self._n_features\n",
    "\n",
    "        k = np.log2(2 + (tp / np.maximum(1,tn)))\n",
    "\n",
    "        X = X * sp.spdiags(k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIcfVectorizer(BaseBinaryFitter,TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Supervised method (supports multiclass) to transform\n",
    "    a count matrix to a normalized Tficf representation\n",
    "    Tf means term-frequency while ICF means inverse category frequency.\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm : 'l1', 'l2', 'max' or None, optional\n",
    "        Norm used to normalize term vectors. None for no normalization.\n",
    "    sublinear_tf : boolean, default=False\n",
    "        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    References\n",
    "    ----------\n",
    "    .. [0] `https://arxiv.org/pdf/1012.2609.pdf`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, norm=None, sublinear_tf=False, smooth_df=False):\n",
    "        self.norm = norm\n",
    "        self.sublinear_tf = sublinear_tf\n",
    "        self.smooth_df = smooth_df\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        pos_samples = sp.spdiags(y, 0, n_samples, n_samples)\n",
    "        neg_samples = sp.spdiags(1 - y, 0, n_samples, n_samples)\n",
    "\n",
    "        X_pos = pos_samples * X\n",
    "        X_neg = neg_samples * X\n",
    "\n",
    "        tp = np.bincount(X_pos.indices, minlength=n_features)\n",
    "        fp = np.sum(y) - tp\n",
    "        tn = np.bincount(X_neg.indices, minlength=n_features)\n",
    "        fn = np.sum(1 - y) - tn\n",
    "        if self.smooth_df:\n",
    "            self._n_samples += int(self.smooth_df)\n",
    "            self._tp += int(self.smooth_df)\n",
    "            self._fp += int(self.smooth_df)\n",
    "            self._fn += int(self.smooth_df)\n",
    "            self._tn += int(self.smooth_df)\n",
    "\n",
    "        samples = []\n",
    "        self.number_of_classes = len(np.unique(y))\n",
    "        for val in range(self.number_of_classes):\n",
    "            class_mask = sp.spdiags(y == val, 0, n_samples, n_samples)\n",
    "            samples.append(np.bincount(\n",
    "                (class_mask * X).indices, minlength=n_features))\n",
    "        samples = np.array(samples)\n",
    "        self.corpus_occurence = np.sum(samples != 0, axis=0)\n",
    "        self.k = (1+np.log(n_samples/(tp+tn))) * (1 + np.log(self.number_of_classes / self.corpus_occurence))\n",
    "        self._n_features = n_features\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, min_freq=1):\n",
    "        if self.sublinear_tf:\n",
    "            X = ensure_sparse_format(X)\n",
    "            np.log(X.data, X.data)\n",
    "            X.data += 1\n",
    "        f = self._n_features\n",
    "        X = X * sp.spdiags(self.k, 0, f, f)\n",
    "        if self.norm:\n",
    "            X = normalize(X, self.norm, copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process (num_attributes, vectorizer, cross_val_num, classifier):\n",
    "  #  clf = svm.SVC(kernel='linear', C=1)\n",
    "    clf = classifier\n",
    "    pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('vetorizer', vectorizer),\n",
    "                     ('reduce_dim', SelectKBest(chi2, k=num_attributes)),\n",
    "                     ('clf', clf)])\n",
    "    scores = cross_val_score(pipe,X.values,y.values,cv=cross_val_num, n_jobs=8)\n",
    "    scores\n",
    "    soma=0\n",
    "    for x in scores:   \n",
    "        soma=soma+x\n",
    "    return soma/cross_val_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAll (array_val, vectorizer, cross_val_num, classifier):\n",
    "    lst = []\n",
    "    \n",
    "    for x in array_val:  \n",
    "        lst.append(process(x, vectorizer, cross_val_num, classifier))\n",
    "\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[500,1000,2000,4000,6000,8000,10000,12000,14000]\n",
    "X,y = readMovieReviewCross()#readSubjectivityCross() #readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_MR = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsSQRTTFIGM_svm_MR_MR = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_MR = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_MR = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_MR = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_MR = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_MR = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_MR = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_MR = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_MR = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_MR = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_MR = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_MR = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_MR = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_MR = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_MR = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_MR = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_MR = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_MR = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_MR = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_MR))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_MR))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_MR))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_MR))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_MR))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_MR))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_MR))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_MR))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_MR))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_MR))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_MR))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_MR))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_MR))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_MR))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_MR))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_MR))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_MR))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_MR))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_MR))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_MR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = readSubjectivityCross() #readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_sub = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_sub = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_sub = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_sub = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_sub = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_sub = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_sub = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_sub = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_sub = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_sub = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_sub = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_sub = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_sub = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_sub = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_sub = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_sub = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_sub = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_sub = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_sub = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_sub = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_sub))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_sub))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_sub))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_sub))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_sub))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_sub))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_sub))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_sub))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_sub))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_sub))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_sub))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_sub))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_sub))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_sub))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_sub))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_sub))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_sub))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_sub))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_sub))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = readSarcasmCross() #readPolarityCross()\n",
    "resultsTFIGM_svm_MR_sar = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_sar = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_sar = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_sar = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsICF_svm_MR_sar = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_sar = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_sar = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_sar = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_sar = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_sar = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_sar = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_sar = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_sar = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_sar = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "resultsICF_mnb_MR_sar = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_sar = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_sar = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_sar = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_sar = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_sar = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_sar))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_sar))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_sar))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_sar))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_sar))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_sar))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_sar))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_sar))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_sar))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_sar))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_sar))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_sar))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_sar))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_sar))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_sar))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_sar))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_sar))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_sar))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_sar))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_sar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity dataset\n",
      "[500, 1000, 2000, 4000, 6000, 8000, 10000, 12000, 14000]\n"
     ]
    }
   ],
   "source": [
    "X,y = readPolarityCross()\n",
    "print (\"Polarity dataset\")\n",
    "print (lst)\n",
    "resultsTFIGM_svm_MR_Pol = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGM_svm_MR_Pol = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIGMimp_svm_MR_Pol = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsSQRTTFIGMimp_svm_MR_Pol = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsICF_svm_MR_Pol = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsDelta_svm_MR_Pol = processAll(lst, TfDELTAidf(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFRFICF_svm_MR_Pol = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTFIDF_svm_MR_Pol = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsTF_svm_MR_Pol = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "resultsRF_svm_Pol = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5, svm.SVC(kernel='linear', C=1))\n",
    "\n",
    "resultsTFIGM_mnb_MR_Pol = processAll(lst, TfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGM_mnb_MR_Pol = processAll(lst, SQRTTfIGMVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIGMimp_mnb_MR_Pol = processAll(lst, TfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsSQRTTFIGMimp_mnb_MR_Pol = processAll(lst, SQRTTfIGMimpVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsICF_mnb_MR_Pol = processAll(lst, TfIcfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsDelta_mnb_MR_Pol = processAll(lst, TfDELTAidf(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFRFICF_mnb_MR_Pol = processAll(lst, TfidfcrfVectorizer1(sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsTFIDF_mnb_MR_Pol = processAll(lst, TfidfTransformer(sublinear_tf=False, smooth_idf=False), 5,MultinomialNB())\n",
    "resultsTF_mnb_MR_Pol = processAll(lst, TfidfTransformer(use_idf=False, sublinear_tf=False), 5,MultinomialNB())\n",
    "resultsRF_mnb_MR_Pol = processAll(lst, TfrfVectorizer(sublinear_tf=False), 5,MultinomialNB())\n",
    "print (\"--SVM-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_svm_MR_Pol))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_svm_MR_Pol))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_svm_MR_Pol))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_svm_MR_Pol))\n",
    "print (\"TFICF - \"+ str(resultsICF_svm_MR_Pol))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_svm_MR_Pol))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_svm_MR_Pol))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_svm_MR_Pol))\n",
    "print (\"TF - \"+ str(resultsTF_svm_MR_Pol))\n",
    "print (\"TFRF - \"+ str(resultsRF_svm_Pol))\n",
    "\n",
    "print (\"--NB-- \")\n",
    "print (\"TFIGM - \"+ str(resultsTFIGM_mnb_MR_Pol))\n",
    "print (\"SQRTTFIGM - \"+ str(resultsSQRTTFIGM_mnb_MR_Pol))\n",
    "print (\"TFIGMimp - \"+ str(resultsTFIGMimp_mnb_MR_Pol))\n",
    "print (\"SQRTTFIGMimp - \"+ str(resultsSQRTTFIGMimp_mnb_MR_Pol))\n",
    "print (\"TFICF - \"+ str(resultsICF_mnb_MR_Pol))\n",
    "print (\"TFDelta - \"+ str(resultsDelta_mnb_MR_Pol))\n",
    "print (\"TFRFICF - \"+ str(resultsTFRFICF_mnb_MR_Pol))\n",
    "print (\"TFIDF - \"+ str(resultsTFIDF_mnb_MR_Pol))\n",
    "print (\"TF - \"+ str(resultsTF_mnb_MR_Pol))\n",
    "print (\"TFRF - \"+ str(resultsRF_mnb_MR_Pol))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
